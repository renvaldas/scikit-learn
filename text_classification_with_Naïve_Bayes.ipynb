{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na誰ve Bayes is a simple but powerful classifier based on a probabilistic model\n",
    "derived from the Bayes' theorem. Basically it determines the probability that an\n",
    "instance belongs to a class based on each of the feature value probabilities. The na誰ve\n",
    "term comes from the fact that it assumes that each feature is independent of the rest,\n",
    "that is, the value of a feature has no relation to the value of another feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite being very simple, it has been used in many domains with very good\n",
    "results. The independence assumption, although a na誰ve and strong simplification,\n",
    "is one of the features that make the model useful in practical applications. Training\n",
    "the model is reduced to the calculation of the involved conditional probabilities,\n",
    "which can be estimated by counting frequencies of correlations between feature\n",
    "values and class values.\n",
    "One of the most successful applications of Na誰ve Bayes has been within the field\n",
    "of Natural Language Processing (NLP). NLP is a field that has been much related\n",
    "to machine learning, since many of its problems can be formulated as a classification\n",
    "task. Usually, NLP problems have important amounts of tagged data in the form\n",
    "of text documents. This data can be used as a training dataset for machine\n",
    "learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset consists of around\n",
    "19,000 newsgroup messages from 20 different topics ranging from politics and\n",
    "religion to sports and science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "IPython version: 4.0.1\n",
      "numpy version: 1.13.1\n",
      "scikit-learn version: 0.18.2\n",
      "matplotlib version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import IPython\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sk.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'numpy.ndarray'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print (type(news.data), type(news.target), type(news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print (news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "18846\n"
     ]
    }
   ],
   "source": [
    "print (len(news.data))\n",
    "print (len(news.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "10 rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print (news.data[0])\n",
    "print (news.target[0], news.target_names[news.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The sklearn.feature_extraction.text module has some useful utilities \n",
    "# to build numeric feature vectors from text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLIT_PERC = 0.75\n",
    "split_size = int(len(news.data)*SPLIT_PERC)\n",
    "X_train = news.data[:split_size]\n",
    "X_test = news.data[split_size:]\n",
    "y_train = news.target[:split_size]\n",
    "y_test = news.target[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look inside the sklearn.feature_extraction.text module, you\n",
    "will find three different classes that can transform text into numeric features:\n",
    "CountVectorizer, HashingVectorizer, and TfidfVectorizer. The difference\n",
    "between them resides in the calculations they perform to obtain the numeric features.\n",
    "CountVectorizer basically creates a dictionary of words from the text corpus. Then,\n",
    "each instance is converted to a vector of numeric features where each element will be\n",
    "the count of the number of times a particular word appears in the document.\n",
    "HashingVectorizer, instead of constricting and maintaining the dictionary in\n",
    "memory, implements a hashing function that maps tokens into feature indexes, and\n",
    "then computes the count as in CountVectorizer.\n",
    "TfidfVectorizer works like the CountVectorizer, but with a more advanced\n",
    "calculation called Term Frequency Inverse Document Frequency (TF-IDF). This is a\n",
    "statistic for measuring the importance of a word in a document or corpus. Intuitively,\n",
    "it looks for words that are more frequent in the current document, compared with\n",
    "their frequency in the whole corpus of documents. You can see this as a way to\n",
    "normalize the results and avoid words that are too frequent, and thus not useful to\n",
    "characterize the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create three different classifiers by combining MultinomialNB with the three\n",
    "different text vectorizers just mentioned, and compare which one performs better\n",
    "using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "\n",
    "clf_1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "clf_2 = Pipeline([\n",
    "    ('vect', HashingVectorizer(non_negative=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "clf_3 = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a function that takes a classifier and performs the K-fold crossvalidation\n",
    "over the specified X and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    # create a k-fold croos validation iterator of k=5 folds\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
    "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will perform a five-fold cross-validation by using each one of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85782493  0.85725657  0.84664367  0.85911382  0.8458477 ]\n",
      "Mean score: 0.853 (+/-0.003)\n",
      "[ 0.75543767  0.77659857  0.77049615  0.78508888  0.76200584]\n",
      "Mean score: 0.770 (+/-0.005)\n",
      "[ 0.84482759  0.85990979  0.84558238  0.85990979  0.84213319]\n",
      "Mean score: 0.850 (+/-0.004)\n"
     ]
    }
   ],
   "source": [
    "clfs = [clf_1, clf_2, clf_3]\n",
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with TfidfVectorizer; we could try to improve the results by trying\n",
    "to parse the text documents into tokens with a different regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_4 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "                token_pattern=r'\\b[a-z0-9_\\-\\.]+[a-z][a-z0->>> 9_\\-\\.]+\\b'\n",
    "    )),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80450928  0.81029451  0.8113558   0.82143805  0.80817193]\n",
      "Mean score: 0.811 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_4, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding stop words\n",
    "def get_stop_words():\n",
    "    result = set()\n",
    "    for line in open(r'data\\stopwords_en.txt', 'r').readlines():\n",
    "        result.add(line.strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_5 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        stop_words= get_stop_words(),\n",
    "        token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88116711  0.89519767  0.88325816  0.89227912  0.88113558]\n",
      "Mean score: 0.887 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_5, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep this vectorizer and start looking at the MultinomialNB parameters. This\n",
    "classifier has few parameters to tweak; the most important is the alpha parameter,\n",
    "which is a smoothing parameter. Let's set it to a lower value; instead of setting alpha\n",
    "to 1.0 (the default value), we will set it to 0.01\n",
    "\n",
    "In Multinomial Naive Bayes, the alpha parameter is what is known as a hyperparameter; i.e. a parameter that controls the form of the model itself. In most cases, the best way to determine optimal values for hyperparameters is through a grid search over possible parameter values, using cross validation to evaluate the performance of the model on your data at each value. Read the above links for details on how to do this with scikit-learn.\n",
    "\n",
    "alpha : float, optional (default=1.0) - Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_7 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        stop_words= get_stop_words(),\n",
    "        token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('clf', MultinomialNB(alpha=0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9204244   0.91960732  0.91828071  0.92677103  0.91854603]\n",
      "Mean score: 0.921 (+/-0.002)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_7, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the performance\n",
    "If we decide that we have made enough improvements in our model, we are ready to\n",
    "evaluate its performance on the testing set.\n",
    "We will define a helper function that will train the model in the entire training set\n",
    "and evaluate the accuracy in the training and in the testing sets. It will also print\n",
    "a classification report (precision and recall on every class) and the corresponding\n",
    "confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print (\"Accuracy on training set:\")\n",
    "    print (clf.score(X_train, y_train))\n",
    "    print (\"Accuracy on testing set:\")\n",
    "    print (clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"Classification Report:\")\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "    print (\"Confusion Matrix:\")\n",
    "    print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.996957690675\n",
      "Accuracy on testing set:\n",
      "0.917869269949\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91       216\n",
      "          1       0.85      0.85      0.85       246\n",
      "          2       0.91      0.84      0.87       274\n",
      "          3       0.81      0.86      0.83       235\n",
      "          4       0.88      0.90      0.89       231\n",
      "          5       0.89      0.91      0.90       225\n",
      "          6       0.88      0.80      0.84       248\n",
      "          7       0.92      0.93      0.93       275\n",
      "          8       0.96      0.98      0.97       226\n",
      "          9       0.97      0.94      0.96       250\n",
      "         10       0.97      1.00      0.98       257\n",
      "         11       0.97      0.97      0.97       261\n",
      "         12       0.90      0.91      0.91       216\n",
      "         13       0.94      0.95      0.95       257\n",
      "         14       0.94      0.97      0.95       246\n",
      "         15       0.90      0.96      0.93       234\n",
      "         16       0.91      0.97      0.94       218\n",
      "         17       0.97      0.99      0.98       236\n",
      "         18       0.95      0.91      0.93       213\n",
      "         19       0.86      0.78      0.82       148\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4712\n",
      "\n",
      "Confusion Matrix:\n",
      "[[190   0   0   0   1   0   0   0   0   1   0   0   0   1   0   9   2   0\n",
      "    0  12]\n",
      " [  0 208   5   3   3  13   4   0   0   0   0   1   3   2   3   0   0   1\n",
      "    0   0]\n",
      " [  0  11 230  22   1   5   1   0   1   0   0   0   0   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   6   6 202   9   3   4   0   0   0   0   0   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   3   4 208   1   5   0   0   0   2   0   5   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   9   2   2   1 205   0   1   1   0   0   0   0   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   3  10   6   0 199  14   1   2   0   1   5   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   1   1   1   1   0   6 257   4   1   0   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   1   2 221   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   2 236   5   0   1   3   0   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0 256   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0 254   0   1   0   0   3   0\n",
      "    1   0]\n",
      " [  0   1   0   1   5   1   3   1   0   2   1   1 197   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   1   1   0   0   0   0   0   0   2   2 245   3   0   1   0\n",
      "    0   1]\n",
      " [  0   2   0   0   1   0   0   1   0   0   0   0   0   1 238   0   1   0\n",
      "    1   1]\n",
      " [  1   0   1   2   0   0   0   1   0   0   0   1   1   0   1 225   0   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   1   0   1   0   0   1   0   0   0   0 212   0\n",
      "    2   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 234\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   2   1   1   0   1   7   3\n",
      "  193   4]\n",
      " [  9   0   0   0   0   1   0   0   0   1   0   0   0   0   0  13   4   1\n",
      "    4 115]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_7, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145767\n"
     ]
    }
   ],
   "source": [
    "# If we look inside the vectorizer, we can see which tokens have been used to create our dictionary\n",
    "print (len(clf_7.named_steps['vect'].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['repay',\n",
       " 'repeal',\n",
       " 'repealed',\n",
       " 'repealing',\n",
       " 'repeat',\n",
       " 'repeat.ps',\n",
       " 'repeatability',\n",
       " 'repeatable',\n",
       " 'repeate',\n",
       " 'repeated',\n",
       " 'repeated-key',\n",
       " 'repeatedly',\n",
       " 'repeater',\n",
       " 'repeating',\n",
       " 'repeats',\n",
       " 'repeattime',\n",
       " 'repectable',\n",
       " 'repel',\n",
       " 'repellant',\n",
       " 'repelled',\n",
       " 'repellent',\n",
       " 'repeller',\n",
       " 'repellers',\n",
       " 'repelling',\n",
       " 'repels',\n",
       " 'repent',\n",
       " 'repentance',\n",
       " 'repentant',\n",
       " 'repented',\n",
       " 'repentence',\n",
       " 'repentently',\n",
       " 'repenting',\n",
       " 'repercussions',\n",
       " 'repertoire',\n",
       " 'repetative',\n",
       " 'repetition',\n",
       " 'repetitions',\n",
       " 'repetitive',\n",
       " 'repetoire',\n",
       " 'rephrase',\n",
       " 'rephrased',\n",
       " 'rephrases',\n",
       " 'rephrasing',\n",
       " 'repinski',\n",
       " 'repitition',\n",
       " 'replacable',\n",
       " 'replace',\n",
       " 'replace-string',\n",
       " 'replaced',\n",
       " 'replaceing']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the feature names.\n",
    "clf_7.named_steps['vect'].get_feature_names()[110000:110050]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that some words are semantically very similar, for example, sand\n",
    "and sands, sanctuaries and sanctuary. Perhaps if the plurals and the singulars are\n",
    "counted to the same bucket, we would better represent the documents. This is a very\n",
    "common task, which could be solved using stemming, a technique that relates two\n",
    "words having the same lexical root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
