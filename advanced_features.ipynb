{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Python version: 3.5.2\n",
      "IPython version: 4.0.1\n",
      "numpy version: 1.13.1\n",
      "scikit-learn version: 0.18.2\n",
      "matplotlib version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import platform\n",
    "import IPython\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print ('Python version:', platform.python_version())\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sk.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapters we have studied several algorithms for very different tasks,\n",
    "from classification and regression to clustering and dimensionality reduction. We\n",
    "showed how we can apply these algorithms to predict results when faced with new\n",
    "data. That is what machine learning is all about. In this last chapter, we want to show\n",
    "some important concepts and methods you should take into account if you want to\n",
    "do real-world machine learning.\n",
    "- In real-world problems, usually data is not already expressed by attribute/\n",
    "float value pairs, but through more complex structures or is not structured at\n",
    "all. We will learn __feature extraction__ techniques that will allow us to extract\n",
    "scikit-learn features from data.\n",
    "- From the initial set of available features, not all of them will be useful\n",
    "for our algorithms to learn from; in fact, some of them may degrade our\n",
    "performance. We will address the problem of selecting the most adequate\n",
    "feature set, a process known as __feature selection__.\n",
    "- Finally, as we have seen in the examples in this book, many of the machine\n",
    "learning algorithms have parameters that must be set in order to use them.\n",
    "To do that, we will review __model selection__ techniques; that is, methods to\n",
    "select the most promising hyperparameters to our algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...the source data does not usually come in this format. We have to\n",
    "extract what we think are potentially useful features and convert them to our learning\n",
    "format. This process is called feature extraction or feature engineering, and it is an\n",
    "often underestimated but very important and time-consuming phase in most realworld\n",
    "machine learning tasks. We can identify two different steps in this task:\n",
    " - __Obtain features__: This step involves processing the source data and extracting\n",
    "the learning instances, usually in the form of feature/value pairs where\n",
    "the value can be an integer or float value, a string, a categorical value, and\n",
    "so on. The method used for extraction depends heavily on how the data\n",
    "is presented. For example, we can have a set of pictures and generate an\n",
    "integer-valued feature for each pixel, indicating its color level, as we did\n",
    "in the face recognition example in Chapter 2, Supervised Learning. Since this\n",
    "is a very task-dependent job, we will not delve into details and assume we\n",
    "already have this setting for our examples.\n",
    " - __Convert features__: Most scikit-learn algorithms assume as an input a set of\n",
    "instances represented as a list of float-valued features. How to get these\n",
    "features will be the main subject of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, as we did in Chapter 2, Supervised Learning, build ad hoc procedures to\n",
    "convert the source data. There are, however, tools that can help us to obtain a\n",
    "suitable representation. The Python package __pandas__ (http://pandas.pydata.\n",
    "org/), for example, provides data structures and tools for data analysis. It aims to\n",
    "provide similar features to those of R, the popular language and environment for\n",
    "statistical computing. We will use pandas to import the Titanic data we presented in\n",
    "Chapter 2, Supervised Learning, and convert them to the scikit-learn format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row.names pclass  survived  \\\n",
      "0          1    1st         1   \n",
      "1          2    1st         0   \n",
      "2          3    1st         0   \n",
      "3          4    1st         0   \n",
      "4          5    1st         1   \n",
      "\n",
      "                                              name      age     embarked  \\\n",
      "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
      "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
      "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
      "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
      "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
      "\n",
      "                         home.dest room      ticket   boat     sex  \n",
      "0                     St Louis, MO  B-5  24160 L221      2  female  \n",
      "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
      "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n"
     ]
    }
   ],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "print (titanic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pclass  survived      age     embarked   boat     sex\n",
      "0    1st         1  29.0000  Southampton      2  female\n",
      "1    1st         0   2.0000  Southampton    NaN  female\n",
      "2    1st         0  30.0000  Southampton  (135)    male\n",
      "3    1st         0  25.0000  Southampton    NaN  female\n",
      "4    1st         1   0.9167  Southampton     11    male\n"
     ]
    }
   ],
   "source": [
    "print (titanic.head()[['pclass', 'survived', 'age', 'embarked',\n",
    "'boat', 'sex']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difficulty we have now is that scikit-learn methods expect real numbers\n",
    "as feature values. In Chapter 2, Supervised Learning, we used the LabelEncoder and\n",
    "OneHotEncoder preprocessing methods to manually convert certain categorical\n",
    "features into 1-of-K values (generating a new feature for each possible value; valued\n",
    "1 if the original feature had the corresponding value and 0 otherwise). This time, we\n",
    "will use a similar scikit-learn method, __DictVectorizer__, which automatically builds\n",
    "these features from the different original feature values. Moreover, we will program\n",
    "a method to encode a set of columns in a unique step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "\n",
    "def one_hot_dataframe(data, cols, replace=False):\n",
    "    vec = feature_extraction.DictVectorizer()\n",
    "    mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
    "    vecData = pd.DataFrame(vec.fit_transform( data[cols].apply(mkdict, axis=1)).toarray())\n",
    "    vecData.columns = vec.get_feature_names()\n",
    "    vecData.index = data.index\n",
    "    if replace:\n",
    "        data = data.drop(cols, axis=1)\n",
    "        data = data.join(vecData)\n",
    "    return (data, vecData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one_hot_dataframe method (based on the script at https://gist.github.\n",
    "com/kljensen/5452382) takes a pandas DataFrame data structure and a list of\n",
    "columns and encodes each column into the necessary 1-of-K features. If the replace\n",
    "parameter is True, it will also substitute the original column with the new set. Let's\n",
    "see it applied to the categorical pclass, embarked, and sex features (titanic_n only\n",
    "contains the previously created columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embarked=Cherbourg</th>\n",
       "      <th>embarked=Queenstown</th>\n",
       "      <th>embarked=Southampton</th>\n",
       "      <th>pclass=1st</th>\n",
       "      <th>pclass=2nd</th>\n",
       "      <th>pclass=3rd</th>\n",
       "      <th>sex=female</th>\n",
       "      <th>sex=male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>633.000000</td>\n",
       "      <td>821</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.341965</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154608</td>\n",
       "      <td>0.034273</td>\n",
       "      <td>0.436405</td>\n",
       "      <td>0.245240</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.541508</td>\n",
       "      <td>0.352628</td>\n",
       "      <td>0.647372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.174762</td>\n",
       "      <td>0.474549</td>\n",
       "      <td>14.747525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>0.181998</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.409760</td>\n",
       "      <td>0.498464</td>\n",
       "      <td>0.477970</td>\n",
       "      <td>0.477970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>985.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         row.names     survived         age  embarked  embarked=Cherbourg  \\\n",
       "count  1313.000000  1313.000000  633.000000       821         1313.000000   \n",
       "mean    657.000000     0.341965   31.194181         0            0.154608   \n",
       "std     379.174762     0.474549   14.747525         0            0.361668   \n",
       "min       1.000000     0.000000    0.166700         0            0.000000   \n",
       "25%     329.000000     0.000000   21.000000         0            0.000000   \n",
       "50%     657.000000     0.000000   30.000000         0            0.000000   \n",
       "75%     985.000000     1.000000   41.000000         0            0.000000   \n",
       "max    1313.000000     1.000000   71.000000         0            1.000000   \n",
       "\n",
       "       embarked=Queenstown  embarked=Southampton   pclass=1st   pclass=2nd  \\\n",
       "count          1313.000000           1313.000000  1313.000000  1313.000000   \n",
       "mean              0.034273              0.436405     0.245240     0.213252   \n",
       "std               0.181998              0.496128     0.430393     0.409760   \n",
       "min               0.000000              0.000000     0.000000     0.000000   \n",
       "25%               0.000000              0.000000     0.000000     0.000000   \n",
       "50%               0.000000              0.000000     0.000000     0.000000   \n",
       "75%               0.000000              1.000000     0.000000     0.000000   \n",
       "max               1.000000              1.000000     1.000000     1.000000   \n",
       "\n",
       "        pclass=3rd   sex=female     sex=male  \n",
       "count  1313.000000  1313.000000  1313.000000  \n",
       "mean      0.541508     0.352628     0.647372  \n",
       "std       0.498464     0.477970     0.477970  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000  \n",
       "50%       1.000000     0.000000     1.000000  \n",
       "75%       1.000000     1.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic,titanic_n = one_hot_dataframe(titanic, ['pclass', 'embarked', 'sex'], replace=True)\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pclass attribute has been converted to three pclass=1st, pclass=2nd,\n",
    "pclass=3rd features, and similarly for the other two features. Note that the\n",
    "embarked feature has not disappeared, This is due to the fact that the original\n",
    "embarked attribute included NaN values, indicating a missing value; in those cases,\n",
    "every feature based on embarked will be valued 0, but the original feature whose\n",
    "value is NaN remains, indicating the feature is missing for certain instances. Next, we\n",
    "encode the remaining categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic, titanic_n = one_hot_dataframe(titanic, ['home.dest', 'room', 'ticket', 'boat'], replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embarked=Cherbourg</th>\n",
       "      <th>embarked=Queenstown</th>\n",
       "      <th>embarked=Southampton</th>\n",
       "      <th>pclass=1st</th>\n",
       "      <th>pclass=2nd</th>\n",
       "      <th>pclass=3rd</th>\n",
       "      <th>...</th>\n",
       "      <th>ticket=248744 L13</th>\n",
       "      <th>ticket=248749 L13</th>\n",
       "      <th>ticket=250647</th>\n",
       "      <th>ticket=27849</th>\n",
       "      <th>ticket=28220 L32 10s</th>\n",
       "      <th>ticket=34218 L10 10s</th>\n",
       "      <th>ticket=36973 L83 9s 6d</th>\n",
       "      <th>ticket=392091</th>\n",
       "      <th>ticket=7076</th>\n",
       "      <th>ticket=L15 1s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>633.000000</td>\n",
       "      <td>821</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.341965</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154608</td>\n",
       "      <td>0.034273</td>\n",
       "      <td>0.436405</td>\n",
       "      <td>0.245240</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.541508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.174762</td>\n",
       "      <td>0.474549</td>\n",
       "      <td>14.747525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361668</td>\n",
       "      <td>0.181998</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>0.430393</td>\n",
       "      <td>0.409760</td>\n",
       "      <td>0.498464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.027597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>985.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         row.names     survived         age  embarked  embarked=Cherbourg  \\\n",
       "count  1313.000000  1313.000000  633.000000       821         1313.000000   \n",
       "mean    657.000000     0.341965   31.194181         0            0.154608   \n",
       "std     379.174762     0.474549   14.747525         0            0.361668   \n",
       "min       1.000000     0.000000    0.166700         0            0.000000   \n",
       "25%     329.000000     0.000000   21.000000         0            0.000000   \n",
       "50%     657.000000     0.000000   30.000000         0            0.000000   \n",
       "75%     985.000000     1.000000   41.000000         0            0.000000   \n",
       "max    1313.000000     1.000000   71.000000         0            1.000000   \n",
       "\n",
       "       embarked=Queenstown  embarked=Southampton   pclass=1st   pclass=2nd  \\\n",
       "count          1313.000000           1313.000000  1313.000000  1313.000000   \n",
       "mean              0.034273              0.436405     0.245240     0.213252   \n",
       "std               0.181998              0.496128     0.430393     0.409760   \n",
       "min               0.000000              0.000000     0.000000     0.000000   \n",
       "25%               0.000000              0.000000     0.000000     0.000000   \n",
       "50%               0.000000              0.000000     0.000000     0.000000   \n",
       "75%               0.000000              1.000000     0.000000     0.000000   \n",
       "max               1.000000              1.000000     1.000000     1.000000   \n",
       "\n",
       "        pclass=3rd      ...        ticket=248744 L13  ticket=248749 L13  \\\n",
       "count  1313.000000      ...              1313.000000        1313.000000   \n",
       "mean      0.541508      ...                 0.000762           0.000762   \n",
       "std       0.498464      ...                 0.027597           0.027597   \n",
       "min       0.000000      ...                 0.000000           0.000000   \n",
       "25%       0.000000      ...                 0.000000           0.000000   \n",
       "50%       1.000000      ...                 0.000000           0.000000   \n",
       "75%       1.000000      ...                 0.000000           0.000000   \n",
       "max       1.000000      ...                 1.000000           1.000000   \n",
       "\n",
       "       ticket=250647  ticket=27849  ticket=28220 L32 10s  \\\n",
       "count    1313.000000   1313.000000           1313.000000   \n",
       "mean        0.000762      0.000762              0.002285   \n",
       "std         0.027597      0.027597              0.047764   \n",
       "min         0.000000      0.000000              0.000000   \n",
       "25%         0.000000      0.000000              0.000000   \n",
       "50%         0.000000      0.000000              0.000000   \n",
       "75%         0.000000      0.000000              0.000000   \n",
       "max         1.000000      1.000000              1.000000   \n",
       "\n",
       "       ticket=34218 L10 10s  ticket=36973 L83 9s 6d  ticket=392091  \\\n",
       "count           1313.000000             1313.000000    1313.000000   \n",
       "mean               0.000762                0.001523       0.001523   \n",
       "std                0.027597                0.039014       0.039014   \n",
       "min                0.000000                0.000000       0.000000   \n",
       "25%                0.000000                0.000000       0.000000   \n",
       "50%                0.000000                0.000000       0.000000   \n",
       "75%                0.000000                0.000000       0.000000   \n",
       "max                1.000000                1.000000       1.000000   \n",
       "\n",
       "       ticket=7076  ticket=L15 1s  \n",
       "count  1313.000000    1313.000000  \n",
       "mean      0.000762       0.000762  \n",
       "std       0.027597       0.027597  \n",
       "min       0.000000       0.000000  \n",
       "25%       0.000000       0.000000  \n",
       "50%       0.000000       0.000000  \n",
       "75%       0.000000       0.000000  \n",
       "max       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 580 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to deal with missing values, since DecisionTreeClassifier we plan\n",
    "to use does not admit them on input. Pandas allow us to replace them with a fixed\n",
    "value using the fillna method. We will use the mean age for the age feature, and 0\n",
    "for the remaining missing attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = titanic['age'].mean()\n",
    "titanic['age'].fillna(mean, inplace=True)\n",
    "titanic.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all of our features (except for Name) are in a suitable format. We are ready to\n",
    "build the test and training sets, as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "titanic_target = titanic['survived']\n",
    "titanic_data = titanic.drop(['name', 'row.names', 'survived'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_data, titanic_target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to simply drop the name attribute, since we do not expect it to be\n",
    "informative about the survival status (we have one different value for each instance,\n",
    "so we can generalize over it). We also specified the survived feature as the target\n",
    "class, and consequently eliminated it from the training vector.\n",
    "Let's see how a decision tree works with the current feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.833 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt = dt.fit(X_train, y_train)\n",
    "from sklearn import metrics\n",
    "y_pred = dt.predict(X_test)\n",
    "print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
